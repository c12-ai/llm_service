#!/bin/bash
# Docker æµ‹è¯•è„šæœ¬ - æµ‹è¯•éƒ¨ç½²çš„å®¹å™¨åŒ–æœåŠ¡

set -e

echo "=========================================="
echo "ðŸ§ª LLM Service Docker æµ‹è¯•"
echo "=========================================="

# æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
if ! docker ps | grep -q qwen-llm-service-cpu; then
    echo "âŒ æœåŠ¡æœªè¿è¡Œ"
    echo "è¯·å…ˆè¿è¡Œ: ./deploy-cpu.sh"
    exit 1
fi

echo ""
echo "âœ… æœåŠ¡æ­£åœ¨è¿è¡Œ"
echo ""

# æµ‹è¯•1: å¥åº·æ£€æŸ¥
echo "æµ‹è¯• 1/5: å¥åº·æ£€æŸ¥..."
HEALTH=$(curl -s http://localhost:8000/health)
if echo "$HEALTH" | grep -q "healthy"; then
    echo "  âœ… å¥åº·æ£€æŸ¥é€šè¿‡"
    echo "  å“åº”: $HEALTH"
else
    echo "  âŒ å¥åº·æ£€æŸ¥å¤±è´¥"
    exit 1
fi

# æµ‹è¯•2: éžæµå¼å¯¹è¯
echo ""
echo "æµ‹è¯• 2/5: éžæµå¼å¯¹è¯..."
RESPONSE=$(curl -s -X POST http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "qwen",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç®€æ´çš„åŠ©æ‰‹ï¼Œå›žç­”è¦ç®€çŸ­ã€‚"},
            {"role": "user", "content": "1+1ç­‰äºŽå‡ ï¼Ÿ"}
        ],
        "max_tokens": 50,
        "temperature": 0.7
    }')

if echo "$RESPONSE" | grep -q "content"; then
    echo "  âœ… éžæµå¼å¯¹è¯æˆåŠŸ"
    CONTENT=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['choices'][0]['message']['content'])" 2>/dev/null || echo "è§£æžå¤±è´¥")
    echo "  æ¨¡åž‹å›žç­”: $CONTENT"
    
    # æ£€æŸ¥ token ç»Ÿè®¡
    if echo "$RESPONSE" | grep -q "usage"; then
        USAGE=$(echo "$RESPONSE" | python3 -c "import sys, json; u=json.load(sys.stdin)['usage']; print(f\"è¾“å…¥={u['prompt_tokens']}, è¾“å‡º={u['completion_tokens']}, æ€»è®¡={u['total_tokens']}\")" 2>/dev/null || echo "è§£æžå¤±è´¥")
        echo "  Token ç»Ÿè®¡: $USAGE"
    fi
else
    echo "  âŒ éžæµå¼å¯¹è¯å¤±è´¥"
    echo "  å“åº”: $RESPONSE"
    exit 1
fi

# æµ‹è¯•3: å¤šè½®å¯¹è¯ï¼ˆå¸¦åŽ†å²ï¼‰
echo ""
echo "æµ‹è¯• 3/5: å¤šè½®å¯¹è¯ï¼ˆå¸¦åŽ†å²ï¼‰..."
RESPONSE=$(curl -s -X POST http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "qwen",
        "messages": [
            {"role": "user", "content": "æˆ‘å«å°æ˜Ž"},
            {"role": "assistant", "content": "ä½ å¥½ï¼Œå°æ˜Žï¼"},
            {"role": "user", "content": "æˆ‘å«ä»€ä¹ˆï¼Ÿ"}
        ],
        "max_tokens": 30
    }')

if echo "$RESPONSE" | grep -q "content"; then
    echo "  âœ… å¤šè½®å¯¹è¯æˆåŠŸ"
    CONTENT=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['choices'][0]['message']['content'])" 2>/dev/null || echo "è§£æžå¤±è´¥")
    echo "  æ¨¡åž‹å›žç­”: $CONTENT"
else
    echo "  âŒ å¤šè½®å¯¹è¯å¤±è´¥"
    exit 1
fi

# æµ‹è¯•4: æµå¼è¾“å‡º
echo ""
echo "æµ‹è¯• 4/5: æµå¼è¾“å‡º..."
STREAM_RESPONSE=$(curl -s -N -X POST http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "qwen",
        "messages": [{"role": "user", "content": "æ•°åˆ°5"}],
        "max_tokens": 50,
        "stream": true
    }')

if echo "$STREAM_RESPONSE" | grep -q "data:"; then
    echo "  âœ… æµå¼è¾“å‡ºæˆåŠŸ"
    echo "  (æ”¶åˆ°æµå¼æ•°æ®å—)"
else
    echo "  âŒ æµå¼è¾“å‡ºå¤±è´¥"
    exit 1
fi

# æµ‹è¯•5: OpenAI SDK å…¼å®¹æ€§ï¼ˆå¦‚æžœå·²å®‰è£…ï¼‰
echo ""
echo "æµ‹è¯• 5/5: OpenAI SDK å…¼å®¹æ€§..."
if command -v python3 &> /dev/null && python3 -c "import openai" 2>/dev/null; then
    python3 << 'EOF'
import openai
import sys

try:
    client = openai.OpenAI(
        api_key="dummy",
        base_url="http://localhost:8000/v1"
    )
    
    response = client.chat.completions.create(
        model="qwen",
        messages=[{"role": "user", "content": "Say OK"}],
        max_tokens=10
    )
    
    print(f"  âœ… OpenAI SDK æµ‹è¯•æˆåŠŸ")
    print(f"  å“åº”: {response.choices[0].message.content}")
except Exception as e:
    print(f"  âŒ OpenAI SDK æµ‹è¯•å¤±è´¥: {e}")
    sys.exit(1)
EOF
else
    echo "  âš ï¸  è·³è¿‡ (æœªå®‰è£… openai åŒ…)"
    echo "     å®‰è£…æ–¹æ³•: pip install openai"
fi

# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
echo ""
echo "=========================================="
echo "ðŸ“Š å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ:"
echo "=========================================="
docker stats qwen-llm-service-cpu --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"

echo ""
echo "=========================================="
echo "ðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼"
echo "=========================================="
echo ""
echo "ðŸ“ æ—¥å¿—æŸ¥çœ‹:"
echo "  docker logs -f qwen-llm-service-cpu"
echo ""
echo "ðŸ›‘ åœæ­¢æœåŠ¡:"
echo "  docker-compose -f docker-compose.cpu.yml down"
echo ""
