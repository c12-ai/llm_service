# Dockerfile for CPU-based LLM Service (本地测试用)
# 基于 transformers 的 CPU 推理

FROM python:3.12.10-slim

# 设置工作目录
WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements-cpu.txt .

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements-cpu.txt

# 复制应用代码
COPY config.py .
COPY llm_service_cpu.py .

# 设置环境变量
ENV MODEL_PATH=/models/Qwen3-4B
ENV MODEL_NAME=Qwen3-4B
ENV SERVICE_HOST=0.0.0.0
ENV SERVICE_PORT=8000
ENV PYTHONUNBUFFERED=1

# 暴露端口
EXPOSE 8000

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 启动服务
CMD ["python", "llm_service_cpu.py"]
